#!/usr/bin/env python3

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt   
from scipy import stats
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm

# set font to Arial
import matplotlib as mpl
mpl.rc('font',family='Arial')

# datasets can be found in accompanying Zenodo repository

all_corrs = np.load('all_corrs.npy') # load daily pattern correlations file

dates = pd.date_range(start='1/1/1940', end='12/31/2023')
dates = dates[~((dates.month == 2) & (dates.day == 29))]
dates = pd.DataFrame(dates)
dates['month'] = pd.to_datetime(dates.iloc[:,0]).dt.month
dates = dates[dates.month.isin([4,5,6,7,8,9])]
dates.reset_index(inplace=True)

day_idx = np.arange(1,184,1)
day_idxs = np.tile(day_idx,83)

# match patterns for each day during 14-day heatwave period (June 15-28, 2023)
for m in range(14):
    corrs = all_corrs[15264+m,:] # starting at day 15264 = 6/15/2023

    df1 = pd.DataFrame({'date':dates.iloc[:,1],'month':dates.month,
                        'corr':corrs})  

    df1['year'] = pd.to_datetime(df1.date).dt.year
    df2 = df1[df1.year<=2022]
    df2['day_idx'] = day_idxs
    df3 = df2[df2.day_idx.between(61+m,91+m)]

    dfx = df3.sort_values(by='corr',ascending=False)
    day_accum = []
    for k in range(df3.shape[0]):
        day = dfx.index.values[k]
        window = list(np.arange(day-3,day+4,1)) # 7-day window
        i, j = window[0], window[-1]
        res = any(ele >= i and ele <= j for ele in day_accum)
        if res == 0:
            day_accum.append(day)
    day_accum = np.array(day_accum)

    df5 = df3.loc[day_accum]
    df8 = df5.iloc[:40] # grab top-40

    mats_idx = df8.index.values

    np.save(f'mats_idx{m}',mats_idx) # save the index of matched days for each of the 14 days during heatwave

# load domain-averaged variables
z500_amjjas2_z = np.load('zvec_smaller.npy')
z500_amjjas2_z = np.nanmax(z500_amjjas2_z,axis=1) # using max of detrended Z500 z-scores in smaller rectangle as predictor

tmax_detrended_z = np.load('tmax_detrended_z.npy')
tmax_z_normed2 = np.load('tmax_z_normed2.npy')
sm_z_normed2 = np.load('sm_z_normed2.npy')

dates = pd.date_range(start='1/1/1940', end='12/31/2023')
dates = dates[~((dates.month == 2) & (dates.day == 29))]
dates = pd.DataFrame(dates)
dates['month'] = pd.to_datetime(dates.iloc[:,0]).dt.month
dates = dates[dates.month.isin([4,5,6,7,8,9])]
idx = dates.index.values

# run predictive models (simple and MLR) for analogs

actuals = []
preds = []
preds_mlr = []
for m in range(14):
    mats_idx = np.load(f'mats_idx{m}.npy') # for each of the 14 heatwave days, load the index of top-40 matched patterns (these were generated by previous code block above)
    
    zv = z500_amjjas2_z
    z = zv[mats_idx]
    tv = tmax_detrended_z # detrended tmax z-scores to train the models
    t = tv[mats_idx]
    
    day = zv[15264+m]
    day2 = tmax_z_normed2[15264+m] # actual z-scores (not detrended)
    actuals.append(day2)
    
    dfx = pd.DataFrame({'z':z,'t':t})
    dfx.dropna(inplace=True)
    X = np.array(dfx.z)
    y = np.array(dfx.t)
    
    X = X.reshape(-1,1)
    y = y.reshape(-1,1)
    reg = LinearRegression().fit(X, y) # fit univariate OLS model

    new_val = np.array(day)
    new_val = new_val.reshape(-1,1)
    preds.append(np.float64(reg.predict(new_val))) # predict domain-averaged Tmax using OLS model
    
    # MLR models
    
    s = sm_z_normed2[mats_idx] # bringin in SM as 2nd predictor
    
    predict_df = pd.DataFrame({'z500':z,
                               'SM':s})
    X = predict_df
    y = pd.DataFrame({'tmax':t})

    model = sm.OLS(y, X).fit() # fitting MLR model using statsmodels package
    
    predict_2023 = np.array([zv[15264+m],sm_z_normed2[15264+m]])
    X_2023 = predict_2023
    preds_mlr.append(np.float64(model.predict(X_2023))) # predict domain-averaged Tmax using MLR model

preds = np.array(preds) # predictions of detrended Tmax z-scores

# first, compute the detrended Tmax values that these z-scores represent
daily_std_detrended = np.load('daily_std_detrended.npy')
std_deg_C = daily_std_detrended[15264:15278]
dep_deg_C = std_deg_C * preds
daily_avg_detrended = np.load('daily_avg_detrended.npy')
pred_deg_C = daily_avg_detrended[15264:15278] + dep_deg_C

# add Tmax trend back in
trend_increments = np.load('tmax_trend_increments.npy')
this_increment = trend_increments[-1]
preds_trend_added = pred_deg_C + this_increment

tmax_normed = np.load('tmax_normed.npy') 
tmax_normed_domain = np.nanmean(tmax_normed,axis=1) # observed domain-average Tmax in actual units (Deg C), latitude normalized
observed_tmax = tmax_normed_domain[15264:15278]

# tie % explained to anomalies in deg C, so they are directly interpretable from panel A
averages = daily_avg_detrended[15264:15278]
full_deps = observed_tmax - averages
perc_explained_circulation = ((pred_deg_C-averages)/full_deps)*100
perc_explained_circulation = np.where(perc_explained_circulation<0,0,perc_explained_circulation)
perc_explained_trend_added = ((preds_trend_added-averages)/full_deps)*100

# repeat the above workflow for MLR

preds_mlr = np.array(preds_mlr)

# first, compute the detrended Tmax values that these z-scores represent
daily_std_detrended = np.load('daily_std_detrended.npy')
std_deg_C = daily_std_detrended[15264:15278]
dep_deg_C_mlr = std_deg_C * preds_mlr
daily_avg_detrended = np.load('daily_avg_detrended.npy')
pred_deg_C_mlr = daily_avg_detrended[15264:15278] + dep_deg_C_mlr

# add Tmax trend back in
trend_increments = np.load('tmax_trend_increments.npy')
this_increment = trend_increments[-1]
preds_trend_added_mlr = pred_deg_C_mlr + this_increment

# tie % explained to anomalies in deg C, so they are directly interpretable from panel A
averages = daily_avg_detrended[15264:15278]
full_deps = observed_tmax - averages
perc_explained_circulation_mlr = ((pred_deg_C_mlr-averages)/full_deps)*100
perc_explained_circulation_mlr = np.where(perc_explained_circulation_mlr<0,0,perc_explained_circulation_mlr)
perc_explained_trend_added_mlr = ((preds_trend_added_mlr-averages)/full_deps)*100

# plot panel A

fig, ax1 = plt.subplots(figsize=(8,6))
ax1.set_ylabel('Domain-averaged Tmax ($^\circ$C)', fontsize = 16)
ax1.set_yticks(np.arange(30,40.01,1))
ax1.set_ylim(top=40)
ax1.set_ylim(bottom=30)
ax1.set_xticks([0,3,6,9,12])
ax1.set_xticklabels(['June 15','June 18','June 21','June 24','June 27'], fontsize = 13)
ax1.plot(observed_tmax,'-o', color='firebrick', lw=2)
ax1.plot(pred_deg_C,'-o', color='0.5', lw=2)
ax1.plot(pred_deg_C_mlr,'-o', color='k', lw=2)
ax1.plot(preds_trend_added_mlr,'-o', color='cornflowerblue', lw=2)
ax1.tick_params(axis='y', labelsize=13)
plt.title('June 15-28, 2023 daily domain-averaged \n Tmax and analog Tmax', fontsize = 20)
plt.savefig('fig_4a.pdf',dpi=600)

# re-plot this on extended y-axis to make legend
fig = plt.figure(figsize=(8,6))
plt.plot(observed_tmax,'-o', color='firebrick', lw=2)
plt.plot(preds_trend_added_mlr,'-o', color='cornflowerblue', lw=2)
plt.plot(pred_deg_C_mlr,'-o', color='k', lw=2)
plt.plot(pred_deg_C,'-o', color='0.5', lw=2)
plt.yticks(np.arange(-5000,6001,1000), fontsize=13)
l = plt.legend(['June 15-28, 2023 Tmax',
            'Tmax predicted by Z500 and SM + Tmax trend',
            'Tmax predicted by Z500 and SM',
            'Tmax predicted by Z500 only'], 
            loc='lower right', fontsize=15)
colors = ['firebrick','cornflowerblue','k','0.5']
n = -1
for text in l.get_texts():
    n += 1
    text.set_color(colors[n])
plt.savefig('fig_4a_legend.pdf',dpi=600)

# plot panel B

fig, ax2 = plt.subplots(figsize=(8,6))
color = 'tab:brown'
ax2.set_ylabel('% of +Tmax anomalies explained', color='k', fontsize=16)  
ax2.set_yticks(np.arange(0,101,10))
ax2.set_ylim(top=102)
ax2.set_ylim(bottom=-2)
ax2.set_xticks([0,3,6,9,12])
ax2.set_xticklabels(['June 15','June 18','June 21','June 24','June 27'], fontsize = 13)
ax2.plot(perc_explained_circulation, '-o', color='0.5', lw=2)
ax2.plot(perc_explained_circulation_mlr, '-o', color='k', lw=2)
ax2.plot(perc_explained_trend_added_mlr, '-o', color='cornflowerblue', lw=2)
ax2.tick_params(axis='y', labelcolor='k')
ax2.tick_params(axis='y', labelsize=13)
plt.title('June 15-28, 2023 percent of \n +Tmax anomalies explained by analogs', fontsize = 20)
plt.show()
plt.savefig('fig_4b.pdf',dpi=600)

# re-plot this on extended y-axis to make legend
fig = plt.figure(figsize=(8,6))
plt.plot(perc_explained_trend_added_mlr, '-o', color='cornflowerblue', lw=2)
plt.plot(perc_explained_trend_added, '-o', color='k', lw=2)
plt.plot(perc_explained_circulation, '-o', color='0.5', lw=2)
plt.yticks(np.arange(-5000,6001,1000), fontsize=13)
l = plt.legend(['% explained by Z500 and SM + Tmax trend',
                '% explained by Z500 and SM',
                '% explained by Z500 only'],
               loc='lower right', fontsize=15)
colors = ['cornflowerblue','k','0.5']
n = -1
for text in l.get_texts():
    n += 1
    text.set_color(colors[n])
plt.savefig('fig_4b_legend.pdf',dpi=600)
